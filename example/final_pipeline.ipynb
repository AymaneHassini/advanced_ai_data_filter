{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nightstalker/miniconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocessing.text import tokenize\n",
    "from database.connect import conn\n",
    "from models.llm import load_llm\n",
    "from models.classifier import load_classifier\n",
    "from tqdm import tqdm\n",
    "from preprocessing.image import preprocess_and_check_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in ./checkpoint. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m load_llm()\n\u001b[0;32m----> 2\u001b[0m trainer, tokenizer \u001b[38;5;241m=\u001b[39m load_classifier()\n",
      "File \u001b[0;32m~/Projects/ml/advanced_ai_data_filter/models/classifier.py:9\u001b[0m, in \u001b[0;36mload_classifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_classifier\u001b[39m():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Preparing the model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     10\u001b[0m         checkpoint, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(checkpoint)\n\u001b[1;32m     13\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     14\u001b[0m         classifier,\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:526\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 526\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    527\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    528\u001b[0m     return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    529\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m    530\u001b[0m     code_revision\u001b[38;5;241m=\u001b[39mcode_revision,\n\u001b[1;32m    531\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    534\u001b[0m )\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1038\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[1;32m   1036\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized model in ./checkpoint. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zoedepth"
     ]
    }
   ],
   "source": [
    "llm = load_llm()\n",
    "trainer, tokenizer = load_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM Baby_Bath_Skin_and_Grooming\") \n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'name',\n",
       "  'main_category',\n",
       "  'sub_category',\n",
       "  'image',\n",
       "  'ratings',\n",
       "  'no_of_ratings',\n",
       "  'discount_price',\n",
       "  'actual_price'],\n",
       " [0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_INDEX = 4\n",
    "PRIMARY_KEY = ['id']\n",
    "\n",
    "columns = [col[0] for col in cursor.description]\n",
    "pk_index = [i for i in range(len(columns)) if columns[i] in PRIMARY_KEY]\n",
    "\n",
    "columns, pk_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1960.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1519.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1527.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1280.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 699.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 294.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2057.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 597.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1738.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1383.35it/s]\n",
      "100%|██████████| 10/10 [00:33<00:00,  3.38s/it]\n"
     ]
    }
   ],
   "source": [
    "results_text = []\n",
    "PK = []\n",
    "indices = []\n",
    "\n",
    "for i in tqdm(range(len(rows[:10]))):    \n",
    "    image = preprocess_and_check_image(rows[i][IMAGE_INDEX])\n",
    "    if image:\n",
    "        prompt = \"Analyze the picture, and the row data.\\nDoes it have a baby picture on it that is seen easily in the package?\"\n",
    "        text_data = \" | \".join([f\"{columns[j]}: {rows[i][j]}\" for j in range(len(columns)) if j != IMAGE_INDEX])\n",
    "        result = llm.generate_content(\n",
    "            [image, \"\\n\\n\", f\"Row data: {text_data}\\n\\n\", prompt]\n",
    "        )\n",
    "        results_text.append(result.text)\n",
    "        dataset_subset = tokenize(result.text, tokenizer)\n",
    "        predictions = trainer.predict(dataset_subset)\n",
    "\n",
    "        predicted_class = np.argmax(predictions.predictions, axis=1)[0]\n",
    "        \n",
    "        if predicted_class <= 2:\n",
    "            indices.append(i)\n",
    "            PK.append([rows[i][j] for j in pk_index])\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Yes, the LuvLap Liquid Cleanser bottle features a prominent picture of a baby playing with a stacking toy. It's clearly visible on the front label.\\n\",\n",
       "  'No, there is no picture of a real baby on the packaging.  It has cartoon drawings of sea creatures and a stylized narwhal on the headrest.\\n',\n",
       "  \"Yes, the packaging clearly displays a stylized image of a baby's head.  It's prominent near the top of the box and on the bottle label.\",\n",
       "  'No, there is no baby picture on the packaging. The image features a lotus flower and meadowsweet graphic.',\n",
       "  \"No, there isn't a clear picture of a baby on the Cetaphil Baby Mild Bar packaging.  There's a stylized image of a baby's bottom being washed with a cloth/puff and some bubbles, but not a distinct photo or drawing of a baby's face.\\n\",\n",
       "  \"No, there is no baby picture readily visible on the packaging in the image. The packaging shows the Johnson's logo and product information.\",\n",
       "  'No, there is no readily visible baby picture on the packaging. There is a stylized heart graphic with \"Baby Moments\" written inside it.',\n",
       "  \"Yes, there is a picture of a baby's face clearly visible on the front of the product packaging.  The baby appears to be wrapped in a towel or blanket.\\n\",\n",
       "  'Yes, there are stylized figures of an adult and a child on the packaging to indicate it can be used for both.',\n",
       "  'No, there is no easily visible baby picture on the packaging. The packaging features the Chicco logo, product name, and images of oats and apricot.'],\n",
       " [[11], [13], [19], [20]],\n",
       " [0, 2, 7, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_text, PK, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_filtered = [rows[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11,\n",
       "  'Luv Lap Liquid Cleanser, Anti-Bacterial, Food Grade, For Baby Bottles, Accessories and Vegetables, 1.5ltr',\n",
       "  'toys & baby products',\n",
       "  'Baby Bath, Skin & Grooming',\n",
       "  'https://m.media-amazon.com/images/I/71p5fCtiCnL._AC_UL320_.jpg',\n",
       "  Decimal('4.40'),\n",
       "  '5,883',\n",
       "  '₹509',\n",
       "  '₹669'),\n",
       " (13,\n",
       "  'The Moms Co. Natural Baby Massage Oil with 10 Oils - Sesame Oil, Avocado, Organic Almond, Organic Jojoba, Organic Chamomil...',\n",
       "  'toys & baby products',\n",
       "  'Baby Bath, Skin & Grooming',\n",
       "  'https://m.media-amazon.com/images/I/71EQE76D+hL._AC_UL320_.jpg',\n",
       "  Decimal('4.40'),\n",
       "  '2,265',\n",
       "  '₹331',\n",
       "  '₹474'),\n",
       " (19,\n",
       "  'BeeBaby Classic Powder Puff with Container for Baby (Blue) | Soft Touch. 100% BPA Free.',\n",
       "  'toys & baby products',\n",
       "  'Baby Bath, Skin & Grooming',\n",
       "  'https://m.media-amazon.com/images/I/61+T2A8EfWL._AC_UL320_.jpg',\n",
       "  Decimal('4.10'),\n",
       "  '1,864',\n",
       "  '₹121',\n",
       "  '₹170'),\n",
       " (20,\n",
       "  'Good knight 100% Natural Mosquito Repellent Fabric Roll-On | Paediatrician Certified | 8-Hour Protect | Citrus - 8 ml',\n",
       "  'toys & baby products',\n",
       "  'Baby Bath, Skin & Grooming',\n",
       "  'https://m.media-amazon.com/images/I/61OUdCB+MOL._AC_UL320_.jpg',\n",
       "  Decimal('4.20'),\n",
       "  '952',\n",
       "  '₹72',\n",
       "  '₹75')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11], [13], [19], [20]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
